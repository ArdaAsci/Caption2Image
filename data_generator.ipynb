{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Project Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import clip\n",
    "from PIL import Image\n",
    "import requests\n",
    "from importlib import reload\n",
    "import io\n",
    "# Import our custom modules\n",
    "import image_loader\n",
    "reload(image_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data From H5 Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"data/eee443_project_dataset_train.h5\", \"r\") as f:\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    train_cap = np.array(f[\"train_cap\"])\n",
    "    train_imid = np.array(f[\"train_imid\"])\n",
    "    #train_ims = np.array(f[\"train_ims\"])\n",
    "    train_url = np.array(f[\"train_url\"])\n",
    "    word_code = np.array(f[\"word_code\"])\n",
    "words = np.array(word_code.dtype.names)\n",
    "word_indices = np.array(list(word_code[0]), dtype=np.int32)\n",
    "with h5py.File(\"data/eee443_project_dataset_test.h5\", \"r\") as f:\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    test_cap = np.array(f[\"test_caps\"])\n",
    "    test_imid = np.array(f[\"test_imid\"])\n",
    "    #test_ims = np.array(f[\"test_ims\"])\n",
    "    test_url = np.array(f[\"test_url\"])\n",
    "train_N = train_cap.shape[0]\n",
    "test_N = test_cap.shape[0]\n",
    "train_cap.shape, train_imid.shape, train_url.shape, test_cap.shape, test_imid.shape, test_url.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load CLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocessor = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load or Calculate Tokenized Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tokenized_train_captions = torch.load(\"data/tokenized_train_captions.pt\", map_location=device)\n",
    "except FileNotFoundError:\n",
    "    ends = np.where(train_cap == 2)[1]\n",
    "    all_caption =  [\"\"] * train_N\n",
    "    for i in range(len(train_cap)):\n",
    "        cap_int = train_cap[i,1:ends[i]]\n",
    "        cap_int = [cap for cap in cap_int if cap not in [0,1,2,3]]\n",
    "        cap = \" \".join(words[cap_int])\n",
    "        all_caption[i] = cap\n",
    "    tokenized_train_captions = clip.tokenize(all_caption).to(device)\n",
    "    torch.save(tokenized_train_captions, \"data/tokenized_train_captions.pt\")\n",
    "try:\n",
    "    tokenized_test_captions = torch.load(\"data/tokenized_test_captions.pt\", map_location=device)\n",
    "except FileNotFoundError:\n",
    "    ends = np.where(test_cap == 2)[1]\n",
    "    all_caption =  [\"\"] * test_N\n",
    "    for i in range(len(test_cap)):\n",
    "        cap_int = test_cap[i,1:ends[i]]\n",
    "        cap_int = [cap for cap in cap_int if cap not in [0,1,2,3]]\n",
    "        cap = \" \".join(words[cap_int])\n",
    "        all_caption[i] = cap\n",
    "    tokenized_test_captions = clip.tokenize(all_caption).to(device)\n",
    "    torch.save(tokenized_test_captions, \"data/tokenized_test_captions.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load or Calculate Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    encoded_train_captions = torch.load(\"data/encoded_train_captions.pt\", map_location=device)\n",
    "except FileNotFoundError:\n",
    "    encoded_train_captions = torch.empty((train_N,512), device=device)\n",
    "    TEXT_ENCODE_BATCH = 1000\n",
    "    with torch.no_grad():\n",
    "        for i in range(train_N//100):\n",
    "            encoded_train_captions[i*TEXT_ENCODE_BATCH:(i+1)*TEXT_ENCODE_BATCH] = model.encode_text(tokenized_train_captions[i*TEXT_ENCODE_BATCH:(i+1)*TEXT_ENCODE_BATCH]).float()\n",
    "            print(f\"Encoded {i*TEXT_ENCODE_BATCH} captions\", end=\"\\r\")\n",
    "    torch.save(encoded_train_captions, \"data/encoded_train_captions.pt\")\n",
    "try:\n",
    "    encoded_test_captions = torch.load(\"data/encoded_test_captions.pt\", map_location=device)\n",
    "except FileNotFoundError:\n",
    "    encoded_test_captions = torch.empty((test_N,512), device=device)\n",
    "    TEXT_ENCODE_BATCH = 1000\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_N//100):\n",
    "            encoded_test_captions[i*TEXT_ENCODE_BATCH:(i+1)*TEXT_ENCODE_BATCH] = model.encode_text(tokenized_test_captions[i*TEXT_ENCODE_BATCH:(i+1)*TEXT_ENCODE_BATCH]).float()\n",
    "            print(f\"Encoded {i*TEXT_ENCODE_BATCH} captions\", end=\"\\r\")\n",
    "    torch.save(encoded_test_captions, \"data/encoded_test_captions.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Tokenized Captions (only needed for caption encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenized_train_captions, tokenized_test_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_image_features = torch.load(\"data/test_image_features.pt\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Test Image Fatures Missing\")\n",
    "try:\n",
    "    train_image_features = torch.load(\"data/train_image_features.pt\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Train Image Fatures Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load URL Health Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    healty_test_urls = np.load(\"data/healty_test_urls.npy\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Healty Test URLs Missing\")\n",
    "try:\n",
    "    healty_train_urls = np.load(\"data/healty_train_urls.npy\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Healty Train URLs Missing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Missing Images from ALL Datasets and Train-Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    test_X = np.load(\"data/test_X.npy\")\n",
    "    test_Y = np.load(\"data/test_Y.npy\")\n",
    "    train_X = np.load(\"data/train_X.npy\")\n",
    "    train_Y = np.load(\"data/train_Y.npy\")\n",
    "    validation_X = np.load(\"data/validation_X.npy\")\n",
    "    validation_Y = np.load(\"data/validation_Y.npy\")\n",
    "    encoded_train_X = torch.load(\"data/encoded_train_X.pt\", map_location=device)\n",
    "    encoded_test_X = torch.load(\"data/encoded_test_X.pt\", map_location=device)\n",
    "    encoded_validation_X = torch.load(\"data/encoded_validation_X.pt\", map_location=device)\n",
    "except FileNotFoundError:\n",
    "    print(\"Data Missing\")\n",
    "    validation_split = 0.1\n",
    "    missing_train_url_indices = np.where(healty_train_urls == False)[0]\n",
    "    missing_test_url_indices = np.where(healty_test_urls == False)[0]\n",
    "    train_missing_data_mask = np.zeros(train_N, dtype=bool)\n",
    "    test_missing_data_mask = np.zeros(test_N, dtype=bool)\n",
    "    for missing_url in missing_train_url_indices:\n",
    "        train_missing_data_mask[train_imid == missing_url] = True\n",
    "    for missing_url in missing_test_url_indices:\n",
    "        test_missing_data_mask[test_imid == missing_url] = True\n",
    "    clean_train_cap = train_cap[~train_missing_data_mask]\n",
    "    clean_train_imid = train_imid[~train_missing_data_mask]\n",
    "    clean_test_cap = test_cap[~test_missing_data_mask]\n",
    "    clean_test_imid = test_imid[~test_missing_data_mask]\n",
    "    clean_encoded_train_cap = encoded_train_captions[~train_missing_data_mask]\n",
    "    clean_encoded_test_cap = encoded_test_captions[~test_missing_data_mask]\n",
    "    clean_test_N = clean_test_cap.shape[0]\n",
    "    clean_train_N = clean_train_cap.shape[0]\n",
    "    val_N = int(validation_split * clean_train_N)\n",
    "    validation_indices = np.random.choice(clean_train_N, val_N, replace=False)\n",
    "    train_indices = np.setdiff1d(np.arange(clean_train_N), validation_indices)\n",
    "    train_X = clean_train_cap[train_indices]\n",
    "    train_Y = clean_train_imid[train_indices]\n",
    "    validation_X = clean_train_cap[validation_indices]\n",
    "    validation_Y = clean_train_imid[validation_indices]\n",
    "    test_X = clean_test_cap\n",
    "    test_Y = clean_test_imid\n",
    "    encoded_train_X = clean_encoded_train_cap[train_indices]\n",
    "    encoded_validation_X = clean_encoded_train_cap[validation_indices]\n",
    "    encoded_test_X = clean_encoded_test_cap\n",
    "    np.save(\"data/train_X.npy\", train_X)\n",
    "    np.save(\"data/train_Y.npy\", train_Y)\n",
    "    np.save(\"data/validation_X.npy\", validation_X)\n",
    "    np.save(\"data/validation_Y.npy\", validation_Y)\n",
    "    np.save(\"data/test_X.npy\", test_X)\n",
    "    np.save(\"data/test_Y.npy\", test_Y)\n",
    "    torch.save(encoded_train_X, \"data/encoded_train_X.pt\")\n",
    "    torch.save(encoded_validation_X, \"data/encoded_validation_X.pt\")\n",
    "    torch.save(encoded_test_X, \"data/encoded_test_X.pt\")\n",
    "    del clean_train_cap, clean_train_imid, clean_test_cap, clean_test_imid\n",
    "    del train_missing_data_mask, test_missing_data_mask\n",
    "    del missing_train_url_indices, missing_test_url_indices\n",
    "    del train_indices, validation_indices\n",
    "train_N = train_X.shape[0]\n",
    "val_N = validation_X.shape[0]\n",
    "test_N = test_X.shape[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6e7149e23e27828e11bcc067cda20e11a8c25d7bde942d0d4ef16e281dfa397"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('hls_env2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
